/**

\page cage Communication and Graph Environment

[cage]: @ref graybat::Cage
[communication policy]: @ref communicationPolicy
[graph policy]: @ref graphPolicy
[pattern]: @ref communicationPattern
[mapping]: @ref mapping


The communication and graph environment ([cage]) provides a
graph-based virtual overlay network which is implemented by the policy
based design. Taking this term to pieces, the [cage] is an interface
which provides communication methods on basis of an existing
communication library, where the possible paths of communication are
described by a graph.

The behavior of the [cage] need to be defined by a
[communication policy] and a [graph policy]. These policies need to be
provided as template arguments to the [cage] class.  The following
listings show examples on how to use and how to configure the [cage]
with predefined [communication policy] and [graph policy].

## Configure the GrayBat Cage ##

1. Include GrayBat umbrella header and predefined functors for
   graph generation and graph mapping.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
#include <graybat.hpp>
#include <pattern/GridDiagonal.hpp>
#include <mapping/Consecutive.hpp>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

2. Define communication policy to use (boost.MPI).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef graybat::communicationPolicy::BMPI CommunicationPolicy;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

3. Define graph policy to use (boost graph library).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef graybat::graphPolicy::BGL<> GraphPolicy;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

4. Define cage through policies.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef graybat::Cage<CommunicatonPolicy, GraphPolicy> Cage;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

5. Create Cage instance with graph creation functor that describes the
   communication [pattern].
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
Cage cage(graybat::pattern::GridDiagonal(100,100))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


## Mapping Operations ##

1. **distribute**: Distributes vertices of the graph to peer(s) based on a [mapping].
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
cage.distribute(graybat::mapping::Consecutive());
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

2. **hostedVertices**: The vertices mapped to the peer itself are called hosted vertices.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef Cage::Vertex Vertex;

// Iterate over all vertices that I host
for(Vertex vertex: cage.hostedVertices){
	std::cout << vertex.id << std::endl;
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## Graph Operations ##

A peer is responsible for the communication of all its hosted
vertices.  Therefore, the common approach for communication in GrayBat
is to iterate over the set of hosted vertices and send data to
adjacent vertices which are connected with an outgoing edge and
receive data from adjacent vertices which are connected with an
incoming edge.

1. **getOutEdges**: Retrieve outgoing edges of hosted vertices. This
   information can be used to send data to adjacent vertices.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef Cage::Edge Edge;
for(Vertex vertex: cage.hostedVertices){
	for(auto outEdge : cage.getOutEdges(vertex)){
    	Vertex destVertex = outEdge.first;
		Edge   destEdge   = outEdge.second;
	}
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

2. **getInEdges**: Retrieve incoming edges of hosted vertices. This
   information can be used to receive data from adjacent vertices.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
for(Vertex vertex: cage.hostedVertices){
	for(auto inEdge : cage.getInEdges(vertex)){
    	Vertex srcVertex = inEdge.first;
		Edge   srcEdge   = inEdge.second;
	}
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


## Point to Point Communication Operations ##

- **send/asyncSend**: Send synchronous and asynchronous data. The
   asynchronous version of send returns an event, which can be waited
   for or tested for its state.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef Cage::Edge  Edge;
typedef Cage::Event Event;

// Some data that should be send
std::vector<int> data(100,1);

for(Vertex vertex: cage.hostedVertices){
	for(auto outEdge : cage.getOutEdges(vertex)){
    	Vertex destVertex = outEdge.first;
		Edge   destEdge   = outEdge.second;

		// Synchronous
		cage.send(destVertex, destEdge, data);

	    // Asynchronous
		Event e = cage.asyncSend(destVertex, destEdge, data);

        // Wait for and test event
		e.wait();
		bool eventState = e.ready();
	}
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


- **recv/asyncRecv**: Receive synchronous and asynchronous data. The
   asynchronous version of recv returns an event, which can be waited
   for or tested for its state.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
typedef Cage::Edge  Edge;
typedef Cage::Event Event;

// Some data that should be send
std::vector<int> data(100,1);

for(Vertex vertex: cage.hostedVertices){
	for(auto inEdge : cage.getInEdges(vertex)){
    	Vertex srcVertex = inEdge.first;
		Edge   srcEdge   = inEdge.second;

	    // Synchronous receive
		cage.recv(destVertex, destEdge, data);

	    // Asynchronous receive
		Event e = cage.asyncRecv(destVertex, destEdge, data);

	    // Wait for and test event
		e.wait();
		bool eventState = e.ready();
	}
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## Collective Communication Operations ##

- **reduce**: Reduce vector of data with binary operator and receive
   by some root vertex.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
Vertex rootVertex = cage.getVertex(0);

std::vector<int> send(100);
std::vector<int> recv(100);

// Each vertex need to reduce its data, the root receives reduction.
for(Vertex vertex: cage.hostedVertices){
	cage.reduce(rootVertex, vertex, std::plus<int>, send, recv);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- **allReduce**: Reduce vector of data and receive them by every vertex.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
std::vector<int> send(100);
std::vector<int> recv(100);

// Each vertex need to reduce its data, all receive reduction.
for(Vertex vertex: cage.hostedVertices){
	cage.allReduce(rootVertex, vertex, std::plus<int>, send, recv);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


- **gather**: Root vertex collects data from each vertex.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
Vertex rootVertex = cage.getVertex(0);

std::vector<int> send(10);
std::vector<int> recv(10 * cage.getVertices().size());

// Each vertex need to send its data, the root receives
for(Vertex vertex: cage.hostedVertices){
	cage.gather(rootVertex, vertex, send, recv);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


- **allGather**: Data is send to all vertices.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
std::vector<int> send(10);
std::vector<int> recv(10 * cage.getVertices().size());

// Each vertex need to send its data, all receive.
for(Vertex vertex: cage.hostedVertices){
	cage.allGather(vertex, send, recv);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- **synchronize**: Synchronize all peers (including their hosted vertices).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.cc}
cage.synchronize();
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## Further Links ##

- \subpage communicationPolicy 
- \subpage graphPolicy 
- \subpage communicationPattern
- \subpage mapping

*/
